{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNoo63P3DQx4ZEvnrXqwoWM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JyotiChowrasia05/PySpark_Steephan/blob/main/PySpark_Steephan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRdCB1xTA4au"
      },
      "outputs": [],
      "source": [
        "#!pip install PySpark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, trim, length,to_timestamp,to_date, coalesce,when, lit, avg"
      ],
      "metadata": {
        "id": "XVOXnqlfF1JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MeteoriteApp\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark Session Created Successfully!\")"
      ],
      "metadata": {
        "id": "QNYnM9m7BqLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the CSV file\n",
        "csv_file_path = \"/content/meteorite_landings_raw.csv\"\n",
        "\n",
        "df = spark.read.csv(\n",
        "    csv_file_path,\n",
        "    header=True,\n",
        "    inferSchema=True\n",
        ")\n",
        "\n",
        "print(f\"\\nDataFrame created from '{csv_file_path}'\")"
      ],
      "metadata": {
        "id": "xV6tQLoBCAbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "1mmwd7RNEmku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "WUDN5pRuEbrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "id": "c6jW0OiXDqqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "jm7PsiUVEYSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_checked = df.withColumn(\n",
        "    \"has_lead_trail_ws\",\n",
        "    (length(col(\"name\")) != length(trim(col(\"name\"))))\n",
        "    .alias(\"has_lead_trail_ws\")\n",
        ")\n",
        "\n",
        "print(\"\\nDataFrame with a flag for leading/trailing whitespace:\")\n",
        "df_checked.show()"
      ],
      "metadata": {
        "id": "9XQRd42sH_9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Triming the whitr space from name column\n",
        "df = df.withColumn(\"name\", trim(col(\"name\")))\n",
        "print(\"\\nDataFrame with 'name' column trimmed:\")\n",
        "df.show()"
      ],
      "metadata": {
        "id": "tcuBA97_FPKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df['year'])"
      ],
      "metadata": {
        "id": "fXewSnfiKc2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert Year column into a date type\n",
        "date_formats = [\n",
        "    \"dd/MM/yyyy hh:mm:ss a\",\n",
        "    \"M/d/yyyy H:mm\"\n",
        "]\n",
        "\n",
        "parsed_date_exp = [to_date(col(\"year\"), fmt) for fmt in date_formats]\n",
        "\n",
        "# Use coalesce to pick the first non-null parsed date\n",
        "df_converted = df.withColumn(\n",
        "    \"converted_date\",\n",
        "    coalesce(*parsed_date_exp) # The '*' unpacks the list into individual arguments\n",
        ")\n",
        "\n",
        "print(\"\\nDataFrame with converted date column (handling multiple formats):\")\n",
        "df_converted.show(truncate=False)\n",
        "df_converted.printSchema()\n"
      ],
      "metadata": {
        "id": "Ds7WyxWfFZvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overwrite the geolocation column to null values where the data is given as (0.000000, 0.000000)\n",
        "zero_coords_string = \"(0.000000, 0.000000)\"\n",
        "\n",
        "df_geo = df.withColumn(\n",
        "    \"geolocation\",\n",
        "    when(\n",
        "        (col(\"geolocation\") == zero_coords_string),\n",
        "         lit(None)\n",
        "    ).otherwise(col(\"geolocation\"))\n",
        ")\n",
        "\n",
        "print(\"\\nDataFrame after nullifying specific geolocation strings:\")\n",
        "df_geo.show(truncate=False)\n",
        "df_geo.printSchema()"
      ],
      "metadata": {
        "id": "7K1yUyaJOiO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average mass of Meteors which fell\n",
        "df_fell = df.filter(\n",
        "    (col(\"fall\") == \"Fell\") &\n",
        "    col(\"mass (g)\").isNotNull() # Exclude null mass values from average\n",
        ")\n",
        "\n",
        "print(\"\\n The records (where column 'fall' has value 'Fell' and column mass is not null):\")\n",
        "print('\\n Total records:', df_fell.count())\n",
        "df_fell.show()\n",
        "\n",
        "avg_mass = df_fell.agg(avg(\"mass (g)\").alias(\"average_mass_fell\"))\n",
        "\n",
        "print(\"\\nAverage mass where 'fall' is 'Fell':\")\n",
        "avg_mass.show()"
      ],
      "metadata": {
        "id": "w1pg5td4ju-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_IvEdD_vjuAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop the SparkSession\n",
        "# spark.stop()\n",
        "# print(\"\\nSparkSession stopped.\")"
      ],
      "metadata": {
        "id": "8rWW02PZE_cG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}